{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which database would you like to scrape: Press 1 for top 250 overall movies; press 2 for top tv shows and 3 for top 250 indian movies2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database==1:\n",
    "    id = \"chart/top/\"\n",
    "elif database==2:\n",
    "    id = \"chart/toptv/\"\n",
    "elif database==3:\n",
    "        id = \"india/top-rated-indian-movies/\"\n",
    "else: print(\"you have to choose in between the three numbers given\")\n",
    "#####hier noch den loop einbauen, dass erneut eine zahl gewählt werden muss oben#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chart/toptv/'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acessing the IMDB 250 web pages\n",
    "headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "page = requests.get(\"https://www.imdb.com/%s\" % id, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "links =[]\n",
    "\n",
    "## Acessing and storing all links of the top 250 movies in a list\n",
    "for a in soup.find_all(\"a\"):\n",
    "    links.append(a.get(\"href\"))\n",
    "links=['https://www.imdb.com'+a.strip() for a in links if a is not None and a.startswith('/title/tt') ]\n",
    "\n",
    "top_250_links=[]\n",
    "for j in links:\n",
    "    if j not in top_250_links:\n",
    "        top_250_links.append(j)\n",
    "## Checking the lentght of the list If 250 all links found\n",
    "print(len(top_250_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the coloumns for the dataframe and creating dataframe where later the scraped information will be appended\n",
    "column_top_250=[\"rank\",\"IMDB_id\", \"movie_name\", \"year\", \"director\", \"starring\", \"rating\", \"number_of_reviews\", \"genres\", \"country\", \"language\", \"budget\", \"box_office_revenue\", \"runtime\"]\n",
    "imdb_top_movies = pd.DataFrame(columns=column_top_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-cc037897eace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m## year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"title_wrapper\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m## loop for directors and actors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Creating a loop to scrape all required infos for the top 250 movies by acessing each stored link\n",
    "\n",
    "for i in np.arange(0, len(top_250_links)):\n",
    "    url = top_250_links[i]\n",
    "    request = requests.get(url, headers=headers)\n",
    "    page = request.text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "   \n",
    "    ## Scraping the IMDB Id directly from the link itself\n",
    "    IMDB_id = str(top_250_links[i][29:-1])\n",
    "    \n",
    "    ## movie_name\n",
    "    movie_name=(soup.find(\"div\",{\"class\":\"title_wrapper\"}).get_text(strip=True).split('|')[0]).split('(')[0]\n",
    "    \n",
    "    ## year\n",
    "    year=((soup.find(\"div\",{\"class\":\"title_wrapper\"}).get_text(strip=True).split('|')[0]).split('(')[1]).split(')')[0]\n",
    "    \n",
    "    ## loop for directors and actors\n",
    "    directors_and_actors=[]\n",
    "    for a in soup.find_all(\"div\",{\"class\":\"credit_summary_item\"}):\n",
    "        c=re.split(\",|:|\\|\",a.get_text(strip=True))   \n",
    "        directors_and_actors.append(c)                                        \n",
    "    actors=directors_and_actors.pop()\n",
    "    writers=directors_and_actors.pop()\n",
    "    directors=directors_and_actors.pop()\n",
    "    if \"See full cast & crew»\" in actors: actors.remove(\"See full cast & crew»\")\n",
    "    if \"1 more credit»\" in directors: directors.remove(\"1 more credit»\")\n",
    "    if \"Stars\" in actors: actors.remove(\"Stars\")\n",
    "    starring=actors[1:]\n",
    "    directors=directors[1:]\n",
    "    \n",
    "    ## director\n",
    "    director=directors[0]\n",
    "        \n",
    "    \n",
    "    ## starring\n",
    "    starring = actors   \n",
    "    \n",
    "    ## rating\n",
    "    rating=soup.find(\"span\",{\"itemprop\":\"ratingValue\"}).text\n",
    "    rating = float(rating.replace(\".\", \"\"))/10\n",
    "    \n",
    "    ## number of reviews\n",
    "    number_of_reviews = soup.find(\"span\",{\"itemprop\":\"ratingCount\"}).text\n",
    "    number_of_reviews = int(number_of_reviews.replace(\",\", \"\"))\n",
    "    \n",
    "    ## Loop for genres\n",
    "    genres_list =[]\n",
    "    for x in soup.find_all(\"div\",{\"class\":\"inline\"}):\n",
    "        d=re.split(\",|:|\\|\",x.get_text(strip=True))\n",
    "        genres_list.append(d)\n",
    "    genres = genres_list.pop()\n",
    "    genres = genres[1:]\n",
    "    \n",
    "    ## Lopp for country and language deetails\n",
    "    b=[]\n",
    "    d={\"Country\":\"\",\"Language\":\"\"}\n",
    "    for a in soup.find_all(\"div\",{\"class\":\"txt-block\"}):\n",
    "        c=a.get_text(strip=True).split(':')\n",
    "        if c[0] in d:\n",
    "            b.append(c)\n",
    "            \n",
    "    for z in b:\n",
    "        if z[0] in d: \n",
    "                d.update({z[0]:z[1]})          \n",
    "    country = d[\"Country\"].split(\"|\")\n",
    "    \n",
    "    ## language\n",
    "    language = d[\"Language\"].split(\"|\")\n",
    "    \n",
    "    ## Commercials\n",
    "    b=[]\n",
    "    d={\"Budget\":\"\",\"Cumulative Worldwide Gross\":\"\"}\n",
    "    for a in soup.find_all(\"div\",{\"class\":\"txt-block\"}):\n",
    "        c=a.get_text(strip=True).split(':')\n",
    "        if c[0] in d:\n",
    "            b.append(c)\n",
    "            \n",
    "    for z in b:\n",
    "        if z[0] in d: \n",
    "                d.update({z[0]:z[1]})                \n",
    "\n",
    "   \n",
    "    box_office_revenue=d['Cumulative Worldwide Gross'].split(' ')[0]\n",
    "    \n",
    "    ## budget\n",
    "    budget=d['Budget']\n",
    "    budget = budget.replace(\"(estimated)\", \"\")\n",
    "    \n",
    "\n",
    "    \n",
    "    ## box office revenue\n",
    "    box_office_revenue=d['Cumulative Worldwide Gross'].split(' ')[0]\n",
    "\n",
    "    \n",
    "    ## runtime\n",
    "      \n",
    "    runtime = soup.find('div', {'id':'titleDetails'}).find('time').text\n",
    "    runtime = int(runtime.replace(\" min\", \"\"))\n",
    "        \n",
    "    movies_dict = {\n",
    "        \"rank\": i+1,\n",
    "        \"IMDB_id\": IMDB_id,\n",
    "        \"movie_name\": movie_name,\n",
    "        \"year\": year,\n",
    "        \"director\": director,\n",
    "        \"starring\": starring, \n",
    "        \"rating\": rating,\n",
    "        \"number_of_reviews\": number_of_reviews,\n",
    "        \"genres\": genres,\n",
    "        \"country\": country,\n",
    "        \"language\": language,\n",
    "        \"budget\": budget,\n",
    "        \"box_office_revenue\": box_office_revenue,\n",
    "        \"runtime\": runtime,\n",
    "    }\n",
    "    \n",
    "    imdb_top_movies = imdb_top_movies.append(pd.DataFrame.from_records([movies_dict],columns=movies_dict.keys()))\n",
    "\n",
    "## string the df with the scraped data in a csv in roder for access to the data in a later stage\n",
    "imdb_top_movies.to_csv(\"imdb_top_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010    46\n",
       "2000    46\n",
       "1990    41\n",
       "1980    29\n",
       "1950    24\n",
       "1970    19\n",
       "1960    19\n",
       "1940    10\n",
       "1920     7\n",
       "1930     6\n",
       "2020     3\n",
       "Name: decades, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## group movies by release years\n",
    "imdb_top_movies = pd.read_csv(\"imdb_top_movies.csv\")\n",
    "imdb_top_movies = imdb_top_movies.astype({\"year\": int})\n",
    "\n",
    "## transofmring into decades\n",
    "imdb_top_movies[\"decades\"] = (imdb_top_movies[\"year\"]//10)*10\n",
    "imdb_top_movies[\"decades\"].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-61c2eeac9133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetpd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'getpd' is not defined"
     ]
    }
   ],
   "source": [
    "getpd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\morit\\\\OneDrive\\\\Desktop\\\\Unterlagen\\\\Uni\\\\FS 21\\\\Programming with advanced computer languages'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
